"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7397],{19773:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Administrator","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Account Pre-reqs","href":"/docusaurus-test/docs/getting-started/Admin/create-account","docId":"getting-started/Admin/create-account","unlisted":false},{"type":"link","label":"Configure Airflow","href":"/docusaurus-test/docs/getting-started/Admin/configure-airflow","docId":"getting-started/Admin/configure-airflow","unlisted":false},{"type":"link","label":"Configure Git Repository","href":"/docusaurus-test/docs/getting-started/Admin/configure-repository","docId":"getting-started/Admin/configure-repository","unlisted":false},{"type":"link","label":"Configure Git Repository Using dbt-coves","href":"/docusaurus-test/docs/getting-started/Admin/configure-repository-using-dbt-coves","docId":"getting-started/Admin/configure-repository-using-dbt-coves","unlisted":false},{"type":"link","label":"Creating Airflow Dags","href":"/docusaurus-test/docs/getting-started/Admin/creating-airflow-dags","docId":"getting-started/Admin/creating-airflow-dags","unlisted":false},{"type":"link","label":"User Management","href":"/docusaurus-test/docs/getting-started/Admin/user-management","docId":"getting-started/Admin/user-management","unlisted":false}],"href":"/docusaurus-test/docs/getting-started/Admin/"},{"type":"category","label":"Developer","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Snowflake Extension","href":"/docusaurus-test/docs/getting-started/developer/snowflake-extension","docId":"getting-started/developer/snowflake-extension","unlisted":false},{"type":"link","label":"Transform Tab","href":"/docusaurus-test/docs/getting-started/developer/transform-tab","docId":"getting-started/developer/transform-tab","unlisted":false},{"type":"link","label":"Using Git","href":"/docusaurus-test/docs/getting-started/developer/using-git","docId":"getting-started/developer/using-git","unlisted":false},{"type":"category","label":"Working with dbt in Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Lineage View","href":"/docusaurus-test/docs/getting-started/developer/working-with-dbt-datacoves/lineage-view","docId":"getting-started/developer/working-with-dbt-datacoves/lineage-view","unlisted":false}],"href":"/docusaurus-test/docs/getting-started/developer/working-with-dbt-datacoves/"}],"href":"/docusaurus-test/docs/getting-started/developer/"}],"href":"/docusaurus-test/docs/getting-started/"},{"type":"category","label":"How to","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Airflow","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Api triggered dag","href":"/docusaurus-test/docs/how-tos/airflow/api-triggered-dag","docId":"how-tos/airflow/api-triggered-dag","unlisted":false},{"type":"link","label":"Create dag level docs","href":"/docusaurus-test/docs/how-tos/airflow/create-dag-level-docs","docId":"how-tos/airflow/create-dag-level-docs","unlisted":false},{"type":"link","label":"Customize worker environment","href":"/docusaurus-test/docs/how-tos/airflow/customize-worker-environment","docId":"how-tos/airflow/customize-worker-environment","unlisted":false},{"type":"link","label":"Dynamically set schedule","href":"/docusaurus-test/docs/how-tos/airflow/dynamically-set-schedule","docId":"how-tos/airflow/dynamically-set-schedule","unlisted":false},{"type":"link","label":"External python dag","href":"/docusaurus-test/docs/how-tos/airflow/external-python-dag","docId":"how-tos/airflow/external-python-dag","unlisted":false},{"type":"link","label":"Generate dags from yml","href":"/docusaurus-test/docs/how-tos/airflow/generate-dags-from-yml","docId":"how-tos/airflow/generate-dags-from-yml","unlisted":false},{"type":"link","label":"Get current branch name","href":"/docusaurus-test/docs/how-tos/airflow/get-current-branch-name","docId":"how-tos/airflow/get-current-branch-name","unlisted":false},{"type":"link","label":"Initial setup","href":"/docusaurus-test/docs/how-tos/airflow/initial-setup","docId":"how-tos/airflow/initial-setup","unlisted":false},{"type":"link","label":"How to Orchestrate your Load","href":"/docusaurus-test/docs/how-tos/airflow/orchestrate-load","docId":"how-tos/airflow/orchestrate-load","unlisted":false},{"type":"link","label":"Request resources on workers","href":"/docusaurus-test/docs/how-tos/airflow/request-resources-on-workers","docId":"how-tos/airflow/request-resources-on-workers","unlisted":false},{"type":"link","label":"Retry dbt tasks","href":"/docusaurus-test/docs/how-tos/airflow/retry-dbt-tasks","docId":"how-tos/airflow/retry-dbt-tasks","unlisted":false},{"type":"link","label":"Run adf pipeline","href":"/docusaurus-test/docs/how-tos/airflow/run-adf-pipeline","docId":"how-tos/airflow/run-adf-pipeline","unlisted":false},{"type":"link","label":"Run airbyte sync jobs","href":"/docusaurus-test/docs/how-tos/airflow/run-airbyte-sync-jobs","docId":"how-tos/airflow/run-airbyte-sync-jobs","unlisted":false},{"type":"link","label":"Run databricks notebook","href":"/docusaurus-test/docs/how-tos/airflow/run-databricks-notebook","docId":"how-tos/airflow/run-databricks-notebook","unlisted":false},{"type":"link","label":"Run dbt","href":"/docusaurus-test/docs/how-tos/airflow/run-dbt","docId":"how-tos/airflow/run-dbt","unlisted":false},{"type":"link","label":"Run fivetran sync jobs","href":"/docusaurus-test/docs/how-tos/airflow/run-fivetran-sync-jobs","docId":"how-tos/airflow/run-fivetran-sync-jobs","unlisted":false},{"type":"link","label":"S3 to snowflake","href":"/docusaurus-test/docs/how-tos/airflow/s3-to-snowflake","docId":"how-tos/airflow/s3-to-snowflake","unlisted":false},{"type":"link","label":"Send emails","href":"/docusaurus-test/docs/how-tos/airflow/send-emails","docId":"how-tos/airflow/send-emails","unlisted":false},{"type":"link","label":"Send ms teams notifications","href":"/docusaurus-test/docs/how-tos/airflow/send-ms-teams-notifications","docId":"how-tos/airflow/send-ms-teams-notifications","unlisted":false},{"type":"link","label":"Send slack notifications","href":"/docusaurus-test/docs/how-tos/airflow/send-slack-notifications","docId":"how-tos/airflow/send-slack-notifications","unlisted":false},{"type":"link","label":"Sync database","href":"/docusaurus-test/docs/how-tos/airflow/sync-database","docId":"how-tos/airflow/sync-database","unlisted":false},{"type":"link","label":"Test dags","href":"/docusaurus-test/docs/how-tos/airflow/test-dags","docId":"how-tos/airflow/test-dags","unlisted":false},{"type":"link","label":"Use airflow api","href":"/docusaurus-test/docs/how-tos/airflow/use-airflow-api","docId":"how-tos/airflow/use-airflow-api","unlisted":false},{"type":"link","label":"Use datacoves secrets manager","href":"/docusaurus-test/docs/how-tos/airflow/use-datacoves-secrets-manager","docId":"how-tos/airflow/use-datacoves-secrets-manager","unlisted":false},{"type":"link","label":"Use variables and connections","href":"/docusaurus-test/docs/how-tos/airflow/use-variables-and-connections","docId":"how-tos/airflow/use-variables-and-connections","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/airflow/"},{"type":"category","label":"DataOps in Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Releasing new feature","href":"/docusaurus-test/docs/how-tos/dataops/releasing-new-feature","docId":"how-tos/dataops/releasing-new-feature","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/dataops/"},{"type":"category","label":"How to use Git","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Ssh keys","href":"/docusaurus-test/docs/how-tos/git/ssh-keys","docId":"how-tos/git/ssh-keys","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/git/"},{"type":"category","label":"Metrics and Logs How Tos","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"View failed git sync","href":"/docusaurus-test/docs/how-tos/metrics-and-logs/view-failed-git-sync","docId":"how-tos/metrics-and-logs/view-failed-git-sync","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/metrics-and-logs/"},{"type":"category","label":"How to set up Snowflake","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Snowflake key based auth","href":"/docusaurus-test/docs/how-tos/snowflake/snowflake-key-based-auth","docId":"how-tos/snowflake/snowflake-key-based-auth","unlisted":false},{"type":"link","label":"Warehouses schemas roles","href":"/docusaurus-test/docs/how-tos/snowflake/warehouses-schemas-roles","docId":"how-tos/snowflake/warehouses-schemas-roles","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/snowflake/"},{"type":"category","label":"My Airflow 101","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Migrating service connections","href":"/docusaurus-test/docs/how-tos/my_airflow/migrating-service-connections","docId":"how-tos/my_airflow/migrating-service-connections","unlisted":false},{"type":"link","label":"My import","href":"/docusaurus-test/docs/how-tos/my_airflow/my-import","docId":"how-tos/my_airflow/my-import","unlisted":false},{"type":"link","label":"Start my airflow","href":"/docusaurus-test/docs/how-tos/my_airflow/start-my-airflow","docId":"how-tos/my_airflow/start-my-airflow","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/my_airflow/"},{"type":"category","label":"Superset in Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"How to Add a Dataset in Superset","href":"/docusaurus-test/docs/how-tos/superset/how_to_data_set","docId":"how-tos/superset/how_to_data_set","unlisted":false},{"type":"link","label":"how_to_database","href":"/docusaurus-test/docs/how-tos/superset/how_to_database","docId":"how-tos/superset/how_to_database","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/superset/"},{"type":"category","label":"Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Add_entraid_app_as_user","href":"/docusaurus-test/docs/how-tos/datacoves/add_entraid_app_as_user","docId":"how-tos/datacoves/add_entraid_app_as_user","unlisted":false},{"type":"link","label":"Authenticate_azure_devops","href":"/docusaurus-test/docs/how-tos/datacoves/authenticate_azure_devops","docId":"how-tos/datacoves/authenticate_azure_devops","unlisted":false},{"type":"link","label":"Create_your_entraid_application","href":"/docusaurus-test/docs/how-tos/datacoves/create_your_entraid_application","docId":"how-tos/datacoves/create_your_entraid_application","unlisted":false},{"type":"link","label":"Gather_azure_devops_auth_details","href":"/docusaurus-test/docs/how-tos/datacoves/gather_azure_devops_auth_details","docId":"how-tos/datacoves/gather_azure_devops_auth_details","unlisted":false},{"type":"link","label":"How_to_configure_aws_secrets_manager","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_configure_aws_secrets_manager","docId":"how-tos/datacoves/how_to_configure_aws_secrets_manager","unlisted":false},{"type":"link","label":"How_to_configure_azure_DevOps","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_configure_azure_DevOps","docId":"how-tos/datacoves/how_to_configure_azure_DevOps","unlisted":false},{"type":"link","label":"How_to_connection_template","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_connection_template","docId":"how-tos/datacoves/how_to_connection_template","unlisted":false},{"type":"link","label":"How_to_environments","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_environments","docId":"how-tos/datacoves/how_to_environments","unlisted":false},{"type":"link","label":"How_to_groups","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_groups","docId":"how-tos/datacoves/how_to_groups","unlisted":false},{"type":"link","label":"How_to_integrations","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_integrations","docId":"how-tos/datacoves/how_to_integrations","unlisted":false},{"type":"link","label":"How_to_invitations","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_invitations","docId":"how-tos/datacoves/how_to_invitations","unlisted":false},{"type":"link","label":"How_to_manage_users","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_manage_users","docId":"how-tos/datacoves/how_to_manage_users","unlisted":false},{"type":"link","label":"How_to_projects","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_projects","docId":"how-tos/datacoves/how_to_projects","unlisted":false},{"type":"link","label":"How_to_secrets","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_secrets","docId":"how-tos/datacoves/how_to_secrets","unlisted":false},{"type":"link","label":"How_to_service_connections","href":"/docusaurus-test/docs/how-tos/datacoves/how_to_service_connections","docId":"how-tos/datacoves/how_to_service_connections","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/datacoves/"},{"type":"category","label":"DataHub in Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"How_to_datahub_cli","href":"/docusaurus-test/docs/how-tos/datahub/how_to_datahub_cli","docId":"how-tos/datahub/how_to_datahub_cli","unlisted":false},{"type":"link","label":"How_to_datahub_dbt","href":"/docusaurus-test/docs/how-tos/datahub/how_to_datahub_dbt","docId":"how-tos/datahub/how_to_datahub_dbt","unlisted":false},{"type":"link","label":"How_to_datahub_snowflake","href":"/docusaurus-test/docs/how-tos/datahub/how_to_datahub_snowflake","docId":"how-tos/datahub/how_to_datahub_snowflake","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/datahub/"},{"type":"category","label":"dbt in Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Advenced dbt debug","href":"/docusaurus-test/docs/how-tos/dbt/advenced-dbt-debug","docId":"how-tos/dbt/advenced-dbt-debug","unlisted":false},{"type":"link","label":"Compilation errors","href":"/docusaurus-test/docs/how-tos/dbt/compilation-errors","docId":"how-tos/dbt/compilation-errors","unlisted":false},{"type":"link","label":"Database errors","href":"/docusaurus-test/docs/how-tos/dbt/database-errors","docId":"how-tos/dbt/database-errors","unlisted":false},{"type":"link","label":"Dependency errors","href":"/docusaurus-test/docs/how-tos/dbt/dependency-errors","docId":"how-tos/dbt/dependency-errors","unlisted":false},{"type":"link","label":"Runtime errors","href":"/docusaurus-test/docs/how-tos/dbt/runtime-errors","docId":"how-tos/dbt/runtime-errors","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/dbt/"},{"type":"category","label":"VS Code in Datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Bigquery_setup","href":"/docusaurus-test/docs/how-tos/vscode/bigquery_setup","docId":"how-tos/vscode/bigquery_setup","unlisted":false},{"type":"link","label":"Databricks_setup","href":"/docusaurus-test/docs/how-tos/vscode/databricks_setup","docId":"how-tos/vscode/databricks_setup","unlisted":false},{"type":"category","label":"AI LLMs for Datacoves Copilot","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Working with an LLM in Datacoves Copilot","href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/llm","docId":"how-tos/vscode/datacoves-copilot/llm","unlisted":false},{"type":"link","label":"V1 llm","href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/v1-llm","docId":"how-tos/vscode/datacoves-copilot/v1-llm","unlisted":false},{"type":"link","label":"V1 llm config","href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/v1-llm-config","docId":"how-tos/vscode/datacoves-copilot/v1-llm-config","unlisted":false},{"type":"link","label":"Datacoves Copilot v1","href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/v1","docId":"how-tos/vscode/datacoves-copilot/v1","unlisted":false},{"type":"link","label":"V2 llm config","href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/v2-llm-config","docId":"how-tos/vscode/datacoves-copilot/v2-llm-config","unlisted":false},{"type":"link","label":"Datacoves Copilot v2","href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/v2","docId":"how-tos/vscode/datacoves-copilot/v2","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/vscode/datacoves-copilot/"},{"type":"link","label":"Environment variables","href":"/docusaurus-test/docs/how-tos/vscode/environment-variables","docId":"how-tos/vscode/environment-variables","unlisted":false},{"type":"link","label":"How to Configure your VS Code in the Datacoves Transform tab","href":"/docusaurus-test/docs/how-tos/vscode/initial","docId":"how-tos/vscode/initial","unlisted":false},{"type":"link","label":"Override","href":"/docusaurus-test/docs/how-tos/vscode/override","docId":"how-tos/vscode/override","unlisted":false},{"type":"link","label":"Redshift_setup","href":"/docusaurus-test/docs/how-tos/vscode/redshift_setup","docId":"how-tos/vscode/redshift_setup","unlisted":false},{"type":"link","label":"Reset git","href":"/docusaurus-test/docs/how-tos/vscode/reset-git","docId":"how-tos/vscode/reset-git","unlisted":false},{"type":"link","label":"Reset user env","href":"/docusaurus-test/docs/how-tos/vscode/reset-user-env","docId":"how-tos/vscode/reset-user-env","unlisted":false},{"type":"link","label":"Snowflake_setup","href":"/docusaurus-test/docs/how-tos/vscode/snowflake_setup","docId":"how-tos/vscode/snowflake_setup","unlisted":false}],"href":"/docusaurus-test/docs/how-tos/vscode/"}],"href":"/docusaurus-test/docs/how-tos/"},{"type":"category","label":"Best Practices","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Git Overview","href":"/docusaurus-test/docs/best-practices/git/","docId":"best-practices/git/README","unlisted":false},{"type":"category","label":"Snowflake","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Security model","href":"/docusaurus-test/docs/best-practices/snowflake/security-model","docId":"best-practices/snowflake/security-model","unlisted":false},{"type":"link","label":"Time travel","href":"/docusaurus-test/docs/best-practices/snowflake/time-travel","docId":"best-practices/snowflake/time-travel","unlisted":false}],"href":"/docusaurus-test/docs/best-practices/snowflake/"},{"type":"category","label":"Best practices on datacoves","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Folder structure","href":"/docusaurus-test/docs/best-practices/datacoves/folder-structure","docId":"best-practices/datacoves/folder-structure","unlisted":false}],"href":"/docusaurus-test/docs/best-practices/datacoves/"},{"type":"category","label":"Overview \x3c!-- {docsify-ignore-all} --\x3e","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Dbt guidelines","href":"/docusaurus-test/docs/best-practices/dbt/dbt-guidelines","docId":"best-practices/dbt/dbt-guidelines","unlisted":false},{"type":"link","label":"Inlets bays coves","href":"/docusaurus-test/docs/best-practices/dbt/inlets-bays-coves","docId":"best-practices/dbt/inlets-bays-coves","unlisted":false},{"type":"link","label":"Object naming","href":"/docusaurus-test/docs/best-practices/dbt/object-naming","docId":"best-practices/dbt/object-naming","unlisted":false}],"href":"/docusaurus-test/docs/best-practices/dbt/"}],"href":"/docusaurus-test/docs/best-practices/"},{"type":"category","label":"Reference","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Datacoves reference","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Versioning","href":"/docusaurus-test/docs/reference/datacoves/versioning","docId":"reference/datacoves/versioning","unlisted":false},{"type":"link","label":"Vpc deployment","href":"/docusaurus-test/docs/reference/datacoves/vpc-deployment","docId":"reference/datacoves/vpc-deployment","unlisted":false}],"href":"/docusaurus-test/docs/reference/datacoves/"},{"type":"link","label":"README","href":"/docusaurus-test/docs/reference/security/","docId":"reference/security/README","unlisted":false},{"type":"category","label":"Metrics & Logs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Grafana","href":"/docusaurus-test/docs/reference/metrics-and-logs/grafana","docId":"reference/metrics-and-logs/grafana","unlisted":false}],"href":"/docusaurus-test/docs/reference/metrics-and-logs/"},{"type":"category","label":"Datacoves Reference","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Csv in datacoves","href":"/docusaurus-test/docs/reference/vscode/csv-in-datacoves","docId":"reference/vscode/csv-in-datacoves","unlisted":false},{"type":"link","label":"Datacoves env vars","href":"/docusaurus-test/docs/reference/vscode/datacoves-env-vars","docId":"reference/vscode/datacoves-env-vars","unlisted":false},{"type":"link","label":"Tips","href":"/docusaurus-test/docs/reference/vscode/tips","docId":"reference/vscode/tips","unlisted":false}],"href":"/docusaurus-test/docs/reference/vscode/"},{"type":"category","label":"Admininstration Menu","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Connection_templates","href":"/docusaurus-test/docs/reference/admin-menu/connection_templates","docId":"reference/admin-menu/connection_templates","unlisted":false},{"type":"link","label":"Environments","href":"/docusaurus-test/docs/reference/admin-menu/environments","docId":"reference/admin-menu/environments","unlisted":false},{"type":"link","label":"Groups","href":"/docusaurus-test/docs/reference/admin-menu/groups","docId":"reference/admin-menu/groups","unlisted":false},{"type":"link","label":"Integrations","href":"/docusaurus-test/docs/reference/admin-menu/integrations","docId":"reference/admin-menu/integrations","unlisted":false},{"type":"link","label":"Invitations","href":"/docusaurus-test/docs/reference/admin-menu/invitations","docId":"reference/admin-menu/invitations","unlisted":false},{"type":"link","label":"Projects","href":"/docusaurus-test/docs/reference/admin-menu/projects","docId":"reference/admin-menu/projects","unlisted":false},{"type":"link","label":"Secrets","href":"/docusaurus-test/docs/reference/admin-menu/secrets","docId":"reference/admin-menu/secrets","unlisted":false},{"type":"link","label":"Service_connections","href":"/docusaurus-test/docs/reference/admin-menu/service_connections","docId":"reference/admin-menu/service_connections","unlisted":false},{"type":"link","label":"Settings_billing","href":"/docusaurus-test/docs/reference/admin-menu/settings_billing","docId":"reference/admin-menu/settings_billing","unlisted":false},{"type":"link","label":"Users","href":"/docusaurus-test/docs/reference/admin-menu/users","docId":"reference/admin-menu/users","unlisted":false}],"href":"/docusaurus-test/docs/reference/admin-menu/"},{"type":"category","label":"Airflow Reference","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Airflow best practices","href":"/docusaurus-test/docs/reference/airflow/airflow-best-practices","docId":"reference/airflow/airflow-best-practices","unlisted":false},{"type":"link","label":"Airflow config defaults","href":"/docusaurus-test/docs/reference/airflow/airflow-config-defaults","docId":"reference/airflow/airflow-config-defaults","unlisted":false},{"type":"link","label":"Airflow variables","href":"/docusaurus-test/docs/reference/airflow/airflow-variables","docId":"reference/airflow/airflow-variables","unlisted":false},{"type":"link","label":"Dag generators","href":"/docusaurus-test/docs/reference/airflow/dag-generators","docId":"reference/airflow/dag-generators","unlisted":false},{"type":"link","label":"Datacoves commands","href":"/docusaurus-test/docs/reference/airflow/datacoves-commands","docId":"reference/airflow/datacoves-commands","unlisted":false},{"type":"link","label":"Datacoves decorators","href":"/docusaurus-test/docs/reference/airflow/datacoves-decorators","docId":"reference/airflow/datacoves-decorators","unlisted":false},{"type":"link","label":"Datacoves operator","href":"/docusaurus-test/docs/reference/airflow/datacoves-operator","docId":"reference/airflow/datacoves-operator","unlisted":false},{"type":"link","label":"Environment service connection vars","href":"/docusaurus-test/docs/reference/airflow/environment-service-connection-vars","docId":"reference/airflow/environment-service-connection-vars","unlisted":false}],"href":"/docusaurus-test/docs/reference/airflow/"}],"href":"/docusaurus-test/docs/reference/"}]},"docs":{"best-practices/datacoves/folder-structure":{"id":"best-practices/datacoves/folder-structure","title":"Folder structure","description":"We recommend organizing your Datacoves project repository as described below so that different components are simple to find and maintain. View our sample analytics project for an example of all the required and recommended folders.","sidebar":"tutorialSidebar"},"best-practices/datacoves/README":{"id":"best-practices/datacoves/README","title":"Best practices on datacoves","description":"Some recommendations on using datacoves.","sidebar":"tutorialSidebar"},"best-practices/dbt/dbt-guidelines":{"id":"best-practices/dbt/dbt-guidelines","title":"Dbt guidelines","description":"dbt Recommendations","sidebar":"tutorialSidebar"},"best-practices/dbt/inlets-bays-coves":{"id":"best-practices/dbt/inlets-bays-coves","title":"Inlets bays coves","description":"Before companies start creating data warehouses or data lakes, they typically run their business with spreadsheets. Different areas of the business do analysis by combining different data sets to produce the metrics they need.","sidebar":"tutorialSidebar"},"best-practices/dbt/object-naming":{"id":"best-practices/dbt/object-naming","title":"Object naming","description":"General Database Relation Naming","sidebar":"tutorialSidebar"},"best-practices/dbt/README":{"id":"best-practices/dbt/README","title":"Overview \x3c!-- {docsify-ignore-all} --\x3e","description":"As any data environment grows, it can become difficult for new team members to unravel complex pieces of logic within the project.","sidebar":"tutorialSidebar"},"best-practices/git/README":{"id":"best-practices/git/README","title":"Git Overview","description":"While many see the advantage of dbt as a platform with unit testing, SQL for everything, and automatic documentation, these have all been available (to various extents) in data platforms for some time. The core innovation that dbt brought to DataOps is Context - the Transformation engine understands the relationship between models.","sidebar":"tutorialSidebar"},"best-practices/README":{"id":"best-practices/README","title":"Best Practices","description":"Here we present some guidance to help you mature your analytics practice. This guidance comes from experience working at large enterprises.","sidebar":"tutorialSidebar"},"best-practices/snowflake/README":{"id":"best-practices/snowflake/README","title":"Snowflake","description":"Here we present some guidance for Snowflake including setting up a scalable security model amd managing time-travel while meeting GDPR requirements.","sidebar":"tutorialSidebar"},"best-practices/snowflake/security-model":{"id":"best-practices/snowflake/security-model","title":"Security model","description":"Overview","sidebar":"tutorialSidebar"},"best-practices/snowflake/time-travel":{"id":"best-practices/snowflake/time-travel","title":"Time travel","description":"In order to comply with GDPRs right to be forgotten, Time Travel for PII data is set at 7 days for Production data, and 21 days for snapshots. Time Travel for non-PII is set to 30 days as default.","sidebar":"tutorialSidebar"},"getting-started/Admin/configure-airflow":{"id":"getting-started/Admin/configure-airflow","title":"Configure Airflow","description":"You don\'t need Airflow to begin using Datacoves, but at some point you will want to schedule your dbt jobs. The following steps will help you get started using Airflow. Keep in mind this is the basic setup, you can find additional Aiflow information in the how-tos and reference sections.","sidebar":"tutorialSidebar"},"getting-started/Admin/configure-repository":{"id":"getting-started/Admin/configure-repository","title":"Configure Git Repository","description":"Now that you have configured your Airflow settings you must ensure that your repository has the correct folder structure to pick up the DAGs we create. You will need to add folders to your project repository in order to match the folder defaults we just configured for Airflow. These folders are orchestrate/dags and, optionally, orchestrate/dagsymldefinitions.","sidebar":"tutorialSidebar"},"getting-started/Admin/configure-repository-using-dbt-coves":{"id":"getting-started/Admin/configure-repository-using-dbt-coves","title":"Configure Git Repository Using dbt-coves","description":"Introduction","sidebar":"tutorialSidebar"},"getting-started/Admin/create-account":{"id":"getting-started/Admin/create-account","title":"Account Pre-reqs","description":"The appropriate git repo access is required to be able to add deployment keys.","sidebar":"tutorialSidebar"},"getting-started/Admin/creating-airflow-dags":{"id":"getting-started/Admin/creating-airflow-dags","title":"Creating Airflow Dags","description":"Pre-Requisites","sidebar":"tutorialSidebar"},"getting-started/Admin/README":{"id":"getting-started/Admin/README","title":"Administrator","description":"Introduction","sidebar":"tutorialSidebar"},"getting-started/Admin/user-management":{"id":"getting-started/Admin/user-management","title":"User Management","description":"1. To get your users up and running, you need to invite them to the platform and grant them access to projects or specific environments.","sidebar":"tutorialSidebar"},"getting-started/developer/README":{"id":"getting-started/developer/README","title":"Developer","description":"Introduction","sidebar":"tutorialSidebar"},"getting-started/developer/snowflake-extension":{"id":"getting-started/developer/snowflake-extension","title":"Snowflake Extension","description":"This getting started video guide covers","sidebar":"tutorialSidebar"},"getting-started/developer/transform-tab":{"id":"getting-started/developer/transform-tab","title":"Transform Tab","description":"This video guide covers:","sidebar":"tutorialSidebar"},"getting-started/developer/using-git":{"id":"getting-started/developer/using-git","title":"Using Git","description":"This guide covers essential Git commands for managing branches and making changes in your Git repository.","sidebar":"tutorialSidebar"},"getting-started/developer/working-with-dbt-datacoves/index":{"id":"getting-started/developer/working-with-dbt-datacoves/index","title":"Working with dbt in Datacoves","description":"This guide covers various aspects of using Datacoves for creating, editing, running, and testing models and sources.","sidebar":"tutorialSidebar"},"getting-started/developer/working-with-dbt-datacoves/lineage-view":{"id":"getting-started/developer/working-with-dbt-datacoves/lineage-view","title":"Lineage View","description":"The Lineage View panel is a feature of the Datacoves VSCode extension that provides a visual representation of the lineage of your project. This tool helps you quickly understand how data flows between models, sources, and downstream dependencies within your dbt project.","sidebar":"tutorialSidebar"},"getting-started/README":{"id":"getting-started/README","title":"Getting Started","description":"","sidebar":"tutorialSidebar"},"how-tos/airflow/api-triggered-dag":{"id":"how-tos/airflow/api-triggered-dag","title":"Api triggered dag","description":"Overview","sidebar":"tutorialSidebar"},"how-tos/airflow/create-dag-level-docs":{"id":"how-tos/airflow/create-dag-level-docs","title":"Create dag level docs","description":"Overview","sidebar":"tutorialSidebar"},"how-tos/airflow/customize-worker-environment":{"id":"how-tos/airflow/customize-worker-environment","title":"Customize worker environment","description":"If you need to run tasks on Airflow on a custom environment that comes with pre-installed libraries and tools, we recommend building your own custom docker image, upload it to a docker image repository such as dockerhub and reference it in your DAG\'s task operator.","sidebar":"tutorialSidebar"},"how-tos/airflow/dynamically-set-schedule":{"id":"how-tos/airflow/dynamically-set-schedule","title":"Dynamically set schedule","description":"By default, DAGs are created with a paused state in Airflow, but you can change this with the ispausedon_creation=True option. However, you will likely not want to schedule DAGs in a development Airflow instance. The steps below describe how do not set a schedule in a Development Airflow instance.","sidebar":"tutorialSidebar"},"how-tos/airflow/external-python-dag":{"id":"how-tos/airflow/external-python-dag","title":"External python dag","description":"If you need additional libraries for your DAG such as pandas, let us know so that we can configure them in your environment.","sidebar":"tutorialSidebar"},"how-tos/airflow/generate-dags-from-yml":{"id":"how-tos/airflow/generate-dags-from-yml","title":"Generate dags from yml","description":"You have the option to write out your DAGs in python or you can write them using yml and then have dbt-coves generate the python DAG for you.","sidebar":"tutorialSidebar"},"how-tos/airflow/get-current-branch-name":{"id":"how-tos/airflow/get-current-branch-name","title":"Get current branch name","description":"In Airflow, Datacoves will place your repo into /opt/airflow/dags/","sidebar":"tutorialSidebar"},"how-tos/airflow/initial-setup":{"id":"how-tos/airflow/initial-setup","title":"Initial setup","description":"Turn on Airflow","sidebar":"tutorialSidebar"},"how-tos/airflow/orchestrate-load":{"id":"how-tos/airflow/orchestrate-load","title":"How to Orchestrate your Load","description":"A service account should already exist that points to your Transform and is named main.","sidebar":"tutorialSidebar"},"how-tos/airflow/README":{"id":"how-tos/airflow/README","title":"Airflow","description":"These how to guides are dedicated to Airflow within Datacoves. Here you will find information on how to Enable and configure Airflow","sidebar":"tutorialSidebar"},"how-tos/airflow/request-resources-on-workers":{"id":"how-tos/airflow/request-resources-on-workers","title":"Request resources on workers","description":"Sometimes you need to run tasks that require more memory or compute power. Airflow task\'s definition that use a kubernetes execution environment allow for this type of configuration.","sidebar":"tutorialSidebar"},"how-tos/airflow/retry-dbt-tasks":{"id":"how-tos/airflow/retry-dbt-tasks","title":"Retry dbt tasks","description":"Overview","sidebar":"tutorialSidebar"},"how-tos/airflow/run-adf-pipeline":{"id":"how-tos/airflow/run-adf-pipeline","title":"Run adf pipeline","description":"You can use Airflow in Datacoves to trigger a Microsoft Azure Data Factory pipeline. This guide will walk you through the configuration process.","sidebar":"tutorialSidebar"},"how-tos/airflow/run-airbyte-sync-jobs":{"id":"how-tos/airflow/run-airbyte-sync-jobs","title":"Run airbyte sync jobs","description":"In our quest to simplify the way tools integrate in the Modern Data Stack, we developed the generate airflow-dags command in the dbt-coves library.","sidebar":"tutorialSidebar"},"how-tos/airflow/run-databricks-notebook":{"id":"how-tos/airflow/run-databricks-notebook","title":"Run databricks notebook","description":"You can use Airflow in Datacoves to trigger a Databricks notebook. This guide will walk you through the configuration process.","sidebar":"tutorialSidebar"},"how-tos/airflow/run-dbt":{"id":"how-tos/airflow/run-dbt","title":"Run dbt","description":"Airflow synchronizes a git repository\'s configured git branch every minute. (The branch specified in  the Git branch name field in the environment\'s DAGs sync configuration)","sidebar":"tutorialSidebar"},"how-tos/airflow/run-fivetran-sync-jobs":{"id":"how-tos/airflow/run-fivetran-sync-jobs","title":"Run fivetran sync jobs","description":"In Addition to triggering Airbyte loads jobs run Airbyte sync jobs you can also trigger Fivetran jobs from your Airflow DAG.","sidebar":"tutorialSidebar"},"how-tos/airflow/s3-to-snowflake":{"id":"how-tos/airflow/s3-to-snowflake","title":"S3 to snowflake","description":"Schema Evolution","sidebar":"tutorialSidebar"},"how-tos/airflow/send-emails":{"id":"how-tos/airflow/send-emails","title":"Send emails","description":"Getting notifications when there is a failure is critical for data teams and Airflow allows multiple ways to keep users informed about the status of a DAG.","sidebar":"tutorialSidebar"},"how-tos/airflow/send-ms-teams-notifications":{"id":"how-tos/airflow/send-ms-teams-notifications","title":"Send ms teams notifications","description":"As stated in how to send email notifications, Airflow allows multiple ways to inform users about DAGs and tasks status.","sidebar":"tutorialSidebar"},"how-tos/airflow/send-slack-notifications":{"id":"how-tos/airflow/send-slack-notifications","title":"Send slack notifications","description":"As stated in how to send email notifications, Airflow allows multiple ways to inform users about DAGs and tasks status.","sidebar":"tutorialSidebar"},"how-tos/airflow/sync-database":{"id":"how-tos/airflow/sync-database","title":"Sync database","description":"It is now possible to synchronize the Datacoves Airflow database to your Data Warehouse","sidebar":"tutorialSidebar"},"how-tos/airflow/test-dags":{"id":"how-tos/airflow/test-dags","title":"Test dags","description":"In Datacoves you can easily test your Airflow DAGs using pytest in the command line. However you can also run these validations in your CI/CD pipeline.","sidebar":"tutorialSidebar"},"how-tos/airflow/use-airflow-api":{"id":"how-tos/airflow/use-airflow-api","title":"Use airflow api","description":"[!WARNING] Users must have Project Level Admin Group to use the Airflow API. The API will allow you to view secrets values in plain text. Always exercise the principle of least privilege.","sidebar":"tutorialSidebar"},"how-tos/airflow/use-datacoves-secrets-manager":{"id":"how-tos/airflow/use-datacoves-secrets-manager","title":"Use datacoves secrets manager","description":"Datacoves includes a built-in Secrets Manager that allows you to securely store and manage secrets for both administrators and developers. Secrets can be stored at the project or environment level and easily shared across other tools in your stack, ensuring seamless integration and enhanced security. Creating or editing a secret in the Datacoves Secret Manager is straightforward. Be sure to prefix all secrets stored in Datacoves Secrets Manager with datacoves-.","sidebar":"tutorialSidebar"},"how-tos/airflow/use-variables-and-connections":{"id":"how-tos/airflow/use-variables-and-connections","title":"Use variables and connections","description":"[!NOTE]dbt-coves generate airflow-dags does not support reading variables/connections, but you may generate the initial Python Airflow DAG and add the connection / variable information.","sidebar":"tutorialSidebar"},"how-tos/datacoves/add_entraid_app_as_user":{"id":"how-tos/datacoves/add_entraid_app_as_user","title":"Add_entraid_app_as_user","description":"Step 1","sidebar":"tutorialSidebar"},"how-tos/datacoves/authenticate_azure_devops":{"id":"how-tos/datacoves/authenticate_azure_devops","title":"Authenticate_azure_devops","description":"Now you are ready to begin configuring your authentication method. This is the method Datacoves will use to clone your repo from Azure DevOps. You have two options: secrets and certificates.","sidebar":"tutorialSidebar"},"how-tos/datacoves/create_your_entraid_application":{"id":"how-tos/datacoves/create_your_entraid_application","title":"Create_your_entraid_application","description":"If you do not have an Entra ID application created, you can do so by following these steps:","sidebar":"tutorialSidebar"},"how-tos/datacoves/gather_azure_devops_auth_details":{"id":"how-tos/datacoves/gather_azure_devops_auth_details","title":"Gather_azure_devops_auth_details","description":"You will need to gather the following application information to configure your project to use Azure DevOps for cloning.","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_configure_aws_secrets_manager":{"id":"how-tos/datacoves/how_to_configure_aws_secrets_manager","title":"How_to_configure_aws_secrets_manager","description":"Table of Contents","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_configure_azure_DevOps":{"id":"how-tos/datacoves/how_to_configure_azure_DevOps","title":"How_to_configure_azure_DevOps","description":"To enable Datacoves cloning from Azure DevOps, you must complete a series of steps outlined in this guide.","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_connection_template":{"id":"how-tos/datacoves/how_to_connection_template","title":"How_to_connection_template","description":"Navigate to the Connection Template page","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_environments":{"id":"how-tos/datacoves/how_to_environments","title":"How_to_environments","description":"Navigate to the Environments page","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_groups":{"id":"how-tos/datacoves/how_to_groups","title":"How_to_groups","description":"Navigate to the groups page in the admin menu","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_integrations":{"id":"how-tos/datacoves/how_to_integrations","title":"How_to_integrations","description":"Navigate to the Integrations Menu","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_invitations":{"id":"how-tos/datacoves/how_to_invitations","title":"How_to_invitations","description":"Navigate to the invitations page","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_manage_users":{"id":"how-tos/datacoves/how_to_manage_users","title":"How_to_manage_users","description":"Navigate to the Users page","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_projects":{"id":"how-tos/datacoves/how_to_projects","title":"How_to_projects","description":"Navigate to the Projects page","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_secrets":{"id":"how-tos/datacoves/how_to_secrets","title":"How_to_secrets","description":"Datacoves includes a built-in Secrets Manager that allows you to securely store and manage secrets for both administrators and developers. Secrets can be stored at the project or environment level and easily shared across other tools in your stack, ensuring seamless integration and enhanced security. Follow this guide to create/edit a secret in the Datacoves Secrets Manager.","sidebar":"tutorialSidebar"},"how-tos/datacoves/how_to_service_connections":{"id":"how-tos/datacoves/how_to_service_connections","title":"How_to_service_connections","description":"Navigate to the Service Connection page","sidebar":"tutorialSidebar"},"how-tos/datacoves/README":{"id":"how-tos/datacoves/README","title":"Datacoves","description":"These how to guides are dedicated to Datacoves admin configurations. See how to configure:","sidebar":"tutorialSidebar"},"how-tos/datahub/how_to_datahub_cli":{"id":"how-tos/datahub/how_to_datahub_cli","title":"How_to_datahub_cli","description":"Connecting to your DataHub instance via your VS Code terminal can be extremely useful for performing maintenance on your metadata, running ingestions, deleting data, and more.","sidebar":"tutorialSidebar"},"how-tos/datahub/how_to_datahub_dbt":{"id":"how-tos/datahub/how_to_datahub_dbt","title":"How_to_datahub_dbt","description":"Prerequisites","sidebar":"tutorialSidebar"},"how-tos/datahub/how_to_datahub_snowflake":{"id":"how-tos/datahub/how_to_datahub_snowflake","title":"How_to_datahub_snowflake","description":"Datahub can ingest Snowflake metadata by connecting to Snowflake directly.","sidebar":"tutorialSidebar"},"how-tos/datahub/README":{"id":"how-tos/datahub/README","title":"DataHub in Datacoves","description":"These how to guides are dedicated to DataHub in Datacoves. See how to:","sidebar":"tutorialSidebar"},"how-tos/dataops/README":{"id":"how-tos/dataops/README","title":"DataOps in Datacoves","description":"These how to guides cover what we define as DataOps best practices.","sidebar":"tutorialSidebar"},"how-tos/dataops/releasing-new-feature":{"id":"how-tos/dataops/releasing-new-feature","title":"Releasing new feature","description":"Releasing a feature into production involves following a development process utilizing Github and GIthub Actions to run automated scripts along with human in the loop approvals as gates to move to the subsequent phase of deployment.","sidebar":"tutorialSidebar"},"how-tos/dbt/advenced-dbt-debug":{"id":"how-tos/dbt/advenced-dbt-debug","title":"Advenced dbt debug","description":"This guide covers advanced debugging techniques for dbt models, providing tools and strategies to diagnose and fix issues in your dbt projects.","sidebar":"tutorialSidebar"},"how-tos/dbt/compilation-errors":{"id":"how-tos/dbt/compilation-errors","title":"Compilation errors","description":"Compilation errors occur when dbt cannot successfully parse your Jinja templates or YAML files. These errors typically appear before any SQL is executed.","sidebar":"tutorialSidebar"},"how-tos/dbt/database-errors":{"id":"how-tos/dbt/database-errors","title":"Database errors","description":"Database errors occur when dbt tries to execute SQL that your database cannot process. These are among the most common errors and are typically straightforward to debug.","sidebar":"tutorialSidebar"},"how-tos/dbt/dependency-errors":{"id":"how-tos/dbt/dependency-errors","title":"Dependency errors","description":"Dependency errors occur when your dbt models reference each other in ways that create conflicts or circular dependencies. These can be some of the most challenging errors to resolve.","sidebar":"tutorialSidebar"},"how-tos/dbt/README":{"id":"how-tos/dbt/README","title":"dbt in Datacoves","description":"These how to guides cover how to resolve common dbt issues","sidebar":"tutorialSidebar"},"how-tos/dbt/runtime-errors":{"id":"how-tos/dbt/runtime-errors","title":"Runtime errors","description":"Runtime errors occur when your dbt project setup is incorrect. These errors typically happen during initial project setup but are less common once your project is properly configured.","sidebar":"tutorialSidebar"},"how-tos/git/README":{"id":"how-tos/git/README","title":"How to use Git","description":"These how to guides cover some Git best practices as well as some setup guides.","sidebar":"tutorialSidebar"},"how-tos/git/ssh-keys":{"id":"how-tos/git/ssh-keys","title":"Ssh keys","description":"Clone a Git repository for development purposes (write access required)","sidebar":"tutorialSidebar"},"how-tos/metrics-and-logs/README":{"id":"how-tos/metrics-and-logs/README","title":"Metrics and Logs How Tos","description":"Datacoves provides Grafana to monitor Airflow, Docker image builds, and more!","sidebar":"tutorialSidebar"},"how-tos/metrics-and-logs/view-failed-git-sync":{"id":"how-tos/metrics-and-logs/view-failed-git-sync","title":"View failed git sync","description":"This how-to will walk you through the steps to view git sync/s3 failures in Grafana.","sidebar":"tutorialSidebar"},"how-tos/my_airflow/migrating-service-connections":{"id":"how-tos/my_airflow/migrating-service-connections","title":"Migrating service connections","description":"To leverage My Airflow and Datacoves Decorators, you\'ll need to update your configurations and refactor your DAGs. This guide walks you through the necessary steps.","sidebar":"tutorialSidebar"},"how-tos/my_airflow/my-import":{"id":"how-tos/my_airflow/my-import","title":"My import","description":"For security purposes, connections and variables do not auto populate from Team Airflow \u27a1\ufe0f My Airflow. This means that every user will need to perform a variable/connection import to their My Airflow. An import will need to be done any time there is a new variable or connection added to keep Team Airflow and My Airflow in sync.  Once connections and variables are added to a user\'s My Airflow they will persist.","sidebar":"tutorialSidebar"},"how-tos/my_airflow/README":{"id":"how-tos/my_airflow/README","title":"My Airflow 101","description":"Datacoves makes it easy to test DAGs quickly with My Airflow, a stand alone user instance of Airflow which tracks whatever branch the user is making changes to in VS Code. My Airflow allows developers to test their DAGs without need to push to their changes to a branch such as airflow_development. My Airflow is meant to test DAG naming, import errors, and basic configurations of a DAG. It has limitations and thus it is important to test your DAG in Team Airflow before pushing to production. That is because Team Airflow is more robust as it is configured to match your Production Airflow instance and runs using the Kubernetes Executor.","sidebar":"tutorialSidebar"},"how-tos/my_airflow/start-my-airflow":{"id":"how-tos/my_airflow/start-my-airflow","title":"Start my airflow","description":"Spin up your individual Airflow instance","sidebar":"tutorialSidebar"},"how-tos/README":{"id":"how-tos/README","title":"How to","description":"How-to guides to help you accomplish a given task assuming you have some basic understanding.","sidebar":"tutorialSidebar"},"how-tos/snowflake/README":{"id":"how-tos/snowflake/README","title":"How to set up Snowflake","description":"These how to guides are dedicated to Snowflake. Learn how to set up different aspects of Snowflake including a proper design of roles and permissions.","sidebar":"tutorialSidebar"},"how-tos/snowflake/snowflake-key-based-auth":{"id":"how-tos/snowflake/snowflake-key-based-auth","title":"Snowflake key based auth","description":"Overview","sidebar":"tutorialSidebar"},"how-tos/snowflake/warehouses-schemas-roles":{"id":"how-tos/snowflake/warehouses-schemas-roles","title":"Warehouses schemas roles","description":"Since we want all changes to the warehouse to be driven by code, we employ Permifrost and some additional scripts to manage changes to Snowflake. (contact us for assistance configuring your repository with the additional scripts needed)","sidebar":"tutorialSidebar"},"how-tos/superset/how_to_data_set":{"id":"how-tos/superset/how_to_data_set","title":"How to Add a Dataset in Superset","description":"To create visualizations you will need to create a dataset which is how a specific view or table is made available to Superset.","sidebar":"tutorialSidebar"},"how-tos/superset/how_to_database":{"id":"how-tos/superset/how_to_database","title":"how_to_database","description":"How to Add a Database Connection in Superset","sidebar":"tutorialSidebar"},"how-tos/superset/README":{"id":"how-tos/superset/README","title":"Superset in Datacoves","description":"These how to guides are dedicated to Superset in Datacoves. See how to:","sidebar":"tutorialSidebar"},"how-tos/vscode/bigquery_setup":{"id":"how-tos/vscode/bigquery_setup","title":"Bigquery_setup","description":"In the Database Connection Section, click Add","sidebar":"tutorialSidebar"},"how-tos/vscode/databricks_setup":{"id":"how-tos/vscode/databricks_setup","title":"Databricks_setup","description":"In the Database Connection Section, click Add","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/llm":{"id":"how-tos/vscode/datacoves-copilot/llm","title":"Working with an LLM in Datacoves Copilot","description":"Once you have configured your LLM, working with the AI chat is a breeze!","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/README":{"id":"how-tos/vscode/datacoves-copilot/README","title":"AI LLMs for Datacoves Copilot","description":"Datacoves can integrate seamlessly with your existing ChatGPT or Azure Open AI LLMs. These how tos will go over configuration and usage of AI within Datacoves.","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/v1":{"id":"how-tos/vscode/datacoves-copilot/v1","title":"Datacoves Copilot v1","description":"This section describes how to configure and use Datacoves Copilot v1.","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/v1-llm":{"id":"how-tos/vscode/datacoves-copilot/v1-llm","title":"V1 llm","description":"Once you have configured your LLM, working with the AI chat is a breeze!","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/v1-llm-config":{"id":"how-tos/vscode/datacoves-copilot/v1-llm-config","title":"V1 llm config","description":"[!NOTE] Datacoves Copilot v1 only support the 4o model gpt model.","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/v2":{"id":"how-tos/vscode/datacoves-copilot/v2","title":"Datacoves Copilot v2","description":"This section describes how to configure and use Datacoves Copilot v2, which comes installed on Datacoves v4+, enhancing the experience and supporting the following LLM providers:","sidebar":"tutorialSidebar"},"how-tos/vscode/datacoves-copilot/v2-llm-config":{"id":"how-tos/vscode/datacoves-copilot/v2-llm-config","title":"V2 llm config","description":"Create a Datacoves Secret","sidebar":"tutorialSidebar"},"how-tos/vscode/environment-variables":{"id":"how-tos/vscode/environment-variables","title":"Environment variables","description":"Table of Contents","sidebar":"tutorialSidebar"},"how-tos/vscode/initial":{"id":"how-tos/vscode/initial","title":"How to Configure your VS Code in the Datacoves Transform tab","description":"When you first log into Datacoves, you will see that VS Code is disabled.","sidebar":"tutorialSidebar"},"how-tos/vscode/override":{"id":"how-tos/vscode/override","title":"Override","description":"Once you have set up your Visual Studio Code environment, you have the possibility to override certain settings we provide by default. This is done in your Workspace settings.","sidebar":"tutorialSidebar"},"how-tos/vscode/README":{"id":"how-tos/vscode/README","title":"VS Code in Datacoves","description":"These how to guides are dedicated to our Hosted VS Code. This powerful IDE gives you all the power you need along with the customization options.","sidebar":"tutorialSidebar"},"how-tos/vscode/redshift_setup":{"id":"how-tos/vscode/redshift_setup","title":"Redshift_setup","description":"In the Database Connection Section, click Add","sidebar":"tutorialSidebar"},"how-tos/vscode/reset-git":{"id":"how-tos/vscode/reset-git","title":"Reset git","description":"If you would like to reset your git clone in your environment, simply delete the .git file with the following command.","sidebar":"tutorialSidebar"},"how-tos/vscode/reset-user-env":{"id":"how-tos/vscode/reset-user-env","title":"Reset user env","description":"If you need to reset your user environment because you change the repo associated with your environment after one has already been cloned or if the repo fails to clone, you will need to remove the workspace folder and reset the environment.","sidebar":"tutorialSidebar"},"how-tos/vscode/snowflake_setup":{"id":"how-tos/vscode/snowflake_setup","title":"Snowflake_setup","description":"Setup Snowflake with Key Pair","sidebar":"tutorialSidebar"},"reference/admin-menu/connection_templates":{"id":"reference/admin-menu/connection_templates","title":"Connection_templates","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/environments":{"id":"reference/admin-menu/environments","title":"Environments","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/groups":{"id":"reference/admin-menu/groups","title":"Groups","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/integrations":{"id":"reference/admin-menu/integrations","title":"Integrations","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/invitations":{"id":"reference/admin-menu/invitations","title":"Invitations","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/projects":{"id":"reference/admin-menu/projects","title":"Projects","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/README":{"id":"reference/admin-menu/README","title":"Admininstration Menu","description":"The Datacoves Administration menu provides access to configurations of projects, environments, users, and connections.","sidebar":"tutorialSidebar"},"reference/admin-menu/secrets":{"id":"reference/admin-menu/secrets","title":"Secrets","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/service_connections":{"id":"reference/admin-menu/service_connections","title":"Service_connections","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/settings_billing":{"id":"reference/admin-menu/settings_billing","title":"Settings_billing","description":"Overview","sidebar":"tutorialSidebar"},"reference/admin-menu/users":{"id":"reference/admin-menu/users","title":"Users","description":"Overview","sidebar":"tutorialSidebar"},"reference/airflow/airflow-best-practices":{"id":"reference/airflow/airflow-best-practices","title":"Airflow best practices","description":"This page should serve as a reference for tips and tricks that we recommend for the best Airflow experience. Please read the official Airflow Best Practices doc first.","sidebar":"tutorialSidebar"},"reference/airflow/airflow-config-defaults":{"id":"reference/airflow/airflow-config-defaults","title":"Airflow config defaults","description":"For security reasons, we do not expose the Airflow config to end users via the Airflow *Admin -> Configuration menu option.","sidebar":"tutorialSidebar"},"reference/airflow/airflow-variables":{"id":"reference/airflow/airflow-variables","title":"Airflow variables","description":"Datacoves injects several environment variables into Apache Airflow to streamline workflow configurations. Below is a list of important variables you may encounter:","sidebar":"tutorialSidebar"},"reference/airflow/dag-generators":{"id":"reference/airflow/dag-generators","title":"Dag generators","description":"Within dbt-coves generate airflow-dags, DAG Generators are responsible of outputting Python code for Airflow Task Groups from other services.","sidebar":"tutorialSidebar"},"reference/airflow/datacoves-commands":{"id":"reference/airflow/datacoves-commands","title":"Datacoves commands","description":"The datacoves bash commands are meant to simplify your workflow. Currently, the datacoves command has the following sub commands:","sidebar":"tutorialSidebar"},"reference/airflow/datacoves-decorators":{"id":"reference/airflow/datacoves-decorators","title":"Datacoves decorators","description":"With the introduction of the task flow API in Airflow we have released the Datacoves decorators to make writing DAGs simple!","sidebar":"tutorialSidebar"},"reference/airflow/datacoves-operator":{"id":"reference/airflow/datacoves-operator","title":"Datacoves operator","description":"[!NOTE] All operators use Datacoves Service connections with Delivery Mode set to Environment Variables","sidebar":"tutorialSidebar"},"reference/airflow/environment-service-connection-vars":{"id":"reference/airflow/environment-service-connection-vars","title":"Environment service connection vars","description":"When creating a service connection and setting the Delivery Mode to environment variables, Datacoves will inject the following environment variables in Airflow.","sidebar":"tutorialSidebar"},"reference/airflow/README":{"id":"reference/airflow/README","title":"Airflow Reference","description":"","sidebar":"tutorialSidebar"},"reference/datacoves/README":{"id":"reference/datacoves/README","title":"Datacoves reference","description":"","sidebar":"tutorialSidebar"},"reference/datacoves/versioning":{"id":"reference/datacoves/versioning","title":"Versioning","description":"Datacoves uses semantic versioning in all our docker images, and Datacoves releases.","sidebar":"tutorialSidebar"},"reference/datacoves/vpc-deployment":{"id":"reference/datacoves/vpc-deployment","title":"Vpc deployment","description":"Datacoves is designed to work on Public or Private Virtual Clouds.","sidebar":"tutorialSidebar"},"reference/metrics-and-logs/grafana":{"id":"reference/metrics-and-logs/grafana","title":"Grafana","description":"Navigation menu","sidebar":"tutorialSidebar"},"reference/metrics-and-logs/README":{"id":"reference/metrics-and-logs/README","title":"Metrics & Logs","description":"The Metrics & Logs menu link provides access to Grafana, where you\'ll find charts that show how services are performing, in addition to a query editor where logs can be analyzed.","sidebar":"tutorialSidebar"},"reference/README":{"id":"reference/README","title":"Reference","description":"Reference guides give you detailed information on a given topic","sidebar":"tutorialSidebar"},"reference/security/README":{"id":"reference/security/README","title":"README","description":"Security and Privacy are fundamental pillars in Datacoves.","sidebar":"tutorialSidebar"},"reference/vscode/csv-in-datacoves":{"id":"reference/vscode/csv-in-datacoves","title":"Csv in datacoves","description":"This page is all about working with CSV files in Datacoves\' VS Code in the browser.","sidebar":"tutorialSidebar"},"reference/vscode/datacoves-env-vars":{"id":"reference/vscode/datacoves-env-vars","title":"Datacoves env vars","description":"Datacoves streamlines your workflow by pre-setting environment variables to simplify work workflow such as the configuration needed to generate Airflow Dags with dbt-coves. You may also leverage these variables for your custom processes. These variables are created automatically and some may be adjusted via the admin settings.","sidebar":"tutorialSidebar"},"reference/vscode/README":{"id":"reference/vscode/README","title":"Datacoves Reference","description":"","sidebar":"tutorialSidebar"},"reference/vscode/tips":{"id":"reference/vscode/tips","title":"Tips","description":"Shortcuts","sidebar":"tutorialSidebar"}}}}')}}]);